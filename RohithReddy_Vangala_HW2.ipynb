{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcPYNjWRGryc"
   },
   "source": [
    "# Deep Learning Assignment - 2\n",
    "# Rohith Reddy Vangala\n",
    "# 016762109\n",
    "# Git Link - https://github.com/rohithreddy66666/Deep_Learning_Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z_n9rJZ6GjVm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load QMNIST dataset and preprocess\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = torchvision.datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "T82-G3zNJKCP",
    "outputId": "e584ba23-5650-4439-d586-7a8c8fadc6e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map for QMNIST labels, which are digits from 0 to 9\n",
    "labels_map = {\n",
    "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
    "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
    "}\n",
    "\n",
    "# Visualization function for the QMNIST dataset\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6enKk-RqJV8_"
   },
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # QMNIST images are 28x28, flatten them to 784 elements\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # Output layer, for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # No softmax needed as it is included in nn.CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d036V4OCJVxN"
   },
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using Adam optimizer with a learning rate of 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3jhZ8c9JpQt",
    "outputId": "3daa858a-686a-4869-fe27-17bd97821f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 1.067873060107231\n",
      "Epoch 1, Batch 200, Loss: 0.43796215012669565\n",
      "Epoch 1, Batch 300, Loss: 0.3709244032204151\n",
      "Epoch 1, Batch 400, Loss: 0.34404019467532637\n",
      "Epoch 1, Batch 500, Loss: 0.33693550325930116\n",
      "Epoch 1, Batch 600, Loss: 0.2948687559366226\n",
      "Epoch 1, Batch 700, Loss: 0.27502964697778226\n",
      "Epoch 1, Batch 800, Loss: 0.2733087466657162\n",
      "Epoch 1, Batch 900, Loss: 0.23646425448358058\n",
      "Epoch 2, Batch 100, Loss: 0.2262163470685482\n",
      "Epoch 2, Batch 200, Loss: 0.19642693035304545\n",
      "Epoch 2, Batch 300, Loss: 0.21162035562098025\n",
      "Epoch 2, Batch 400, Loss: 0.19451099269092084\n",
      "Epoch 2, Batch 500, Loss: 0.20591210290789605\n",
      "Epoch 2, Batch 600, Loss: 0.1994524972140789\n",
      "Epoch 2, Batch 700, Loss: 0.16944984134286642\n",
      "Epoch 2, Batch 800, Loss: 0.1702181687951088\n",
      "Epoch 2, Batch 900, Loss: 0.17726700846105814\n",
      "Epoch 3, Batch 100, Loss: 0.15099807469174265\n",
      "Epoch 3, Batch 200, Loss: 0.15550436828285455\n",
      "Epoch 3, Batch 300, Loss: 0.1469092752225697\n",
      "Epoch 3, Batch 400, Loss: 0.1458630245551467\n",
      "Epoch 3, Batch 500, Loss: 0.1384270314872265\n",
      "Epoch 3, Batch 600, Loss: 0.12664872398599983\n",
      "Epoch 3, Batch 700, Loss: 0.1297372136823833\n",
      "Epoch 3, Batch 800, Loss: 0.13195757839828728\n",
      "Epoch 3, Batch 900, Loss: 0.12522968957200648\n",
      "Epoch 4, Batch 100, Loss: 0.11175606449134648\n",
      "Epoch 4, Batch 200, Loss: 0.11392422363162041\n",
      "Epoch 4, Batch 300, Loss: 0.11515903349965811\n",
      "Epoch 4, Batch 400, Loss: 0.09594333574175834\n",
      "Epoch 4, Batch 500, Loss: 0.12342320477589964\n",
      "Epoch 4, Batch 600, Loss: 0.11887137856334448\n",
      "Epoch 4, Batch 700, Loss: 0.11271952452138066\n",
      "Epoch 4, Batch 800, Loss: 0.11995855500921607\n",
      "Epoch 4, Batch 900, Loss: 0.11668192030861974\n",
      "Epoch 5, Batch 100, Loss: 0.09619536459445953\n",
      "Epoch 5, Batch 200, Loss: 0.09192752962000668\n",
      "Epoch 5, Batch 300, Loss: 0.0857514718035236\n",
      "Epoch 5, Batch 400, Loss: 0.09478371975012123\n",
      "Epoch 5, Batch 500, Loss: 0.0882006011530757\n",
      "Epoch 5, Batch 600, Loss: 0.10687285730615258\n",
      "Epoch 5, Batch 700, Loss: 0.10570047414395958\n",
      "Epoch 5, Batch 800, Loss: 0.08665307716466486\n",
      "Epoch 5, Batch 900, Loss: 0.09566088749095797\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "num_epochs = 5  #  number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBTrOhssKGvp",
    "outputId": "7f95b7c2-fde7-4a59-fe34-64ca41b334df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 95.44%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # No gradients needed for evaluation\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QK24OFBuKd6g"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model and store predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())  # Ensure to move predictions to CPU if running on GPU\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "KOnM2N-OKmCo",
    "outputId": "fea68dbd-2278-4b1f-8b64-33f482a4b465"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of test images and labels\n",
    "images, labels = next(iter(test_loader))\n",
    "image, true_label = images[6], labels[6]  # Select the seventh image for checking\n",
    "\n",
    "# Predict the label for the selected image\n",
    "with torch.no_grad():  # No need for gradient computation here\n",
    "    output = model(image.unsqueeze(0))  # batch dimension\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = \"Correct\" if predicted_label == true_label else \"Incorrect\"\n",
    "\n",
    "# Visualize the image and prediction result\n",
    "plt.imshow(image.squeeze(), cmap='gray')  # Remove channel dimension for visualization\n",
    "plt.title(f'Predicted: {predicted_label.item()}, Actual: {true_label.item()} - {is_correct}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEZ7iczeaDCd"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUniWYNkNE3H"
   },
   "source": [
    "# Hypothesis - Adding Additional Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B5j8k8bdNH_X"
   },
   "outputs": [],
   "source": [
    "# Define the neural network architecture with an additional dense layer\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # First dense layer\n",
    "        self.fc2 = nn.Linear(128, 128)      # New second dense layer with 128 nodes\n",
    "        self.fc3 = nn.Linear(128, 64)       # Third dense layer\n",
    "        self.fc4 = nn.Linear(64, 10)        # Output layer, for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # No softmax needed as it is included in nn.CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network with the additional layer\n",
    "model = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_tOtQyXNdbS",
    "outputId": "611f5993-f70c-4487-bf11-2c7d821e9e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 1.1511580380797386\n",
      "Epoch 1, Batch 200, Loss: 0.5202640342712402\n",
      "Epoch 1, Batch 300, Loss: 0.40703219816088676\n",
      "Epoch 1, Batch 400, Loss: 0.34866170793771745\n",
      "Epoch 1, Batch 500, Loss: 0.3315189203619957\n",
      "Epoch 1, Batch 600, Loss: 0.29834427058696744\n",
      "Epoch 1, Batch 700, Loss: 0.2708351005613804\n",
      "Epoch 1, Batch 800, Loss: 0.2696481337025762\n",
      "Epoch 1, Batch 900, Loss: 0.24486232809722425\n",
      "Epoch 2, Batch 100, Loss: 0.21920586213469506\n",
      "Epoch 2, Batch 200, Loss: 0.2217395618930459\n",
      "Epoch 2, Batch 300, Loss: 0.19843594051897526\n",
      "Epoch 2, Batch 400, Loss: 0.18794058002531527\n",
      "Epoch 2, Batch 500, Loss: 0.18682972088456154\n",
      "Epoch 2, Batch 600, Loss: 0.17440885953605176\n",
      "Epoch 2, Batch 700, Loss: 0.17229453671723605\n",
      "Epoch 2, Batch 800, Loss: 0.15519943587481977\n",
      "Epoch 2, Batch 900, Loss: 0.16032762175425888\n",
      "Epoch 3, Batch 100, Loss: 0.14325539663434028\n",
      "Epoch 3, Batch 200, Loss: 0.15707981890067457\n",
      "Epoch 3, Batch 300, Loss: 0.1355794319882989\n",
      "Epoch 3, Batch 400, Loss: 0.131865842230618\n",
      "Epoch 3, Batch 500, Loss: 0.13184779625386\n",
      "Epoch 3, Batch 600, Loss: 0.1426170901954174\n",
      "Epoch 3, Batch 700, Loss: 0.12753000965341926\n",
      "Epoch 3, Batch 800, Loss: 0.14492474509403108\n",
      "Epoch 3, Batch 900, Loss: 0.12013909259811044\n",
      "Epoch 4, Batch 100, Loss: 0.10774872877635061\n",
      "Epoch 4, Batch 200, Loss: 0.11084025807678699\n",
      "Epoch 4, Batch 300, Loss: 0.10840353881940246\n",
      "Epoch 4, Batch 400, Loss: 0.11248006578534842\n",
      "Epoch 4, Batch 500, Loss: 0.10593937094323337\n",
      "Epoch 4, Batch 600, Loss: 0.11314197096973658\n",
      "Epoch 4, Batch 700, Loss: 0.12871234498918058\n",
      "Epoch 4, Batch 800, Loss: 0.10369775224477053\n",
      "Epoch 4, Batch 900, Loss: 0.10711553033441305\n",
      "Epoch 5, Batch 100, Loss: 0.09185498395003379\n",
      "Epoch 5, Batch 200, Loss: 0.08580779928714037\n",
      "Epoch 5, Batch 300, Loss: 0.09576654020696879\n",
      "Epoch 5, Batch 400, Loss: 0.0984593837801367\n",
      "Epoch 5, Batch 500, Loss: 0.08883688132744283\n",
      "Epoch 5, Batch 600, Loss: 0.09538508550729602\n",
      "Epoch 5, Batch 700, Loss: 0.09173599944449962\n",
      "Epoch 5, Batch 800, Loss: 0.09029884530231357\n",
      "Epoch 5, Batch 900, Loss: 0.09382214183919131\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "num_epochs = 5  # You can adjust the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKVvUidRNhb-",
    "outputId": "88f0967a-db08-4265-d88a-04fe4d14792f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 96.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # No gradients needed for evaluation\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "RtPd3YQROL8o",
    "outputId": "e4b12545-2765-4501-9b17-bd57191f255c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of test images and labels\n",
    "images, labels = next(iter(test_loader))\n",
    "image, true_label = images[6], labels[6]  # Select the seventh image for checking\n",
    "\n",
    "# Predict the label for the selected image\n",
    "with torch.no_grad():  # No need for gradient computation here\n",
    "    output = model(image.unsqueeze(0))  # Add a batch dimension\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "\n",
    "# Check if the prediction is correct\n",
    "is_correct = \"Correct\" if predicted_label == true_label else \"Incorrect\"\n",
    "\n",
    "# Visualize the image and prediction result\n",
    "plt.imshow(image.squeeze(), cmap='gray')  # Remove channel dimension for visualization\n",
    "plt.title(f'Predicted: {predicted_label.item()}, Actual: {true_label.item()} - {is_correct}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xferBqh3OOzR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iz2WZdKKOme5"
   },
   "source": [
    "Adding one more layer to the neural network made it a bit better at figuring out the QMNIST handwritten numbers. Before, the accuracy was 95.44%, but after the change, it went up to 96.62%. This means the network got smarter at knowing the difference between the numbers it had seen before and new ones it hadn't. With more nodes to work with, the network could spot more details and patterns that helped it get the right answers more often. But just because it's doing better now doesn't mean it will always get it right, especially with new numbers it hasn't learned yet. So, it's good to keep checking to make sure it's still learning the right things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C8Oj-t2aTc_"
   },
   "source": [
    "# Hypothesis - Testing with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0NJ2f3dOnsZ",
    "outputId": "6a1d7e4b-cbf6-402a-8185-aae2caf528b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using SGD: 92.15%\n",
      "Accuracy using Adam: 96.10%\n",
      "Accuracy using RMSprop: 96.04%\n"
     ]
    }
   ],
   "source": [
    "# Redefine the MLP class to avoid any potential conflicts\n",
    "class ModifiedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)  # Additional layer\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "# Function to perform training and evaluation\n",
    "def train_and_evaluate(optimizer_class, lr, model, train_loader, test_loader, criterion, num_epochs=5):\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Optimizers to test\n",
    "optimizers_to_test = [\n",
    "    (optim.SGD, 0.01),\n",
    "    (optim.Adam, 0.001),\n",
    "    (optim.RMSprop, 0.001)\n",
    "]\n",
    "\n",
    "# Training and evaluation loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for optimizer_class, lr in optimizers_to_test:\n",
    "    # Reinitialize the model for each optimizer\n",
    "    model = ModifiedMLP()\n",
    "    accuracy = train_and_evaluate(optimizer_class, lr, model, train_loader, test_loader, criterion)\n",
    "    print(f'Accuracy using {optimizer_class.__name__}: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fvh4s4xTLpO"
   },
   "source": [
    "Adam and RMSprop outperformed SGD due to their adaptive learning rate mechanisms, which allow them to dynamically adjust the learning rate for each parameter based on the magnitude of recent gradients. SGD, on the other hand, uses a fixed learning rate for all parameters throughout training. This adaptability enables Adam and RMSprop to effectively navigate the complex and sometimes erratic landscape of the loss function, allowing for quicker convergence and better generalization. Adam maintains separate adaptive learning rates for each parameter, which are estimated from the first and second moments of the gradients. This ensures that the learning rate is appropriately scaled for each parameter, leading to more efficient optimization. Similarly, RMSprop scales the learning rate for each parameter based on the exponentially weighted moving average of the squared gradients, effectively mitigating the issue of oscillations in the parameter updates and allowing for more stable training. Thus, the superior performance of Adam and RMSprop on the QMNIST dataset can be attributed to their ability to adaptively adjust the learning rates, resulting in more effective and efficient optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqEoYM_OabuX"
   },
   "source": [
    "# Testing With Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWCR1YuyTMvX",
    "outputId": "a1d9705b-b77d-43fa-ca64-0a62700ad03e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using CrossEntropyLoss: 96.15%\n",
      "Accuracy using NLLLoss: 95.74%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a list of loss functions to test\n",
    "loss_functions = {\n",
    "    'CrossEntropyLoss': nn.CrossEntropyLoss(),\n",
    "    'NLLLoss': nn.NLLLoss(),\n",
    "    # Add more loss functions as needed\n",
    "}\n",
    "\n",
    "# Training and evaluation loop\n",
    "for loss_name, loss_func in loss_functions.items():\n",
    "    # Reinitialize the model for each loss function\n",
    "    model = ModifiedMLP()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reinitialize optimizer\n",
    "    criterion = loss_func  # Set the criterion to the current loss function\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            if loss_name == 'NLLLoss':\n",
    "                outputs = F.log_softmax(outputs, dim=1)  # Apply log softmax for NLLLoss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            if loss_name == 'NLLLoss':\n",
    "                outputs = F.log_softmax(outputs, dim=1)  # Apply log softmax for NLLLoss\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy using {loss_name}: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k1SnIQHV2_B"
   },
   "source": [
    " both CrossEntropyLoss and NLLLoss are suitable for the classification task, with CrossEntropyLoss being a more convenient choice as it combines log softmax and negative log likelihood in a single function so yeilded the high accuracy with 96.15 when compared with the nllloss. However, the accuracy achieved with NLLLoss demonstrates that it can also yield accurate results when properly applied with the appropriate model architecture adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfraWrieagK0"
   },
   "source": [
    "# Testing With Different Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gt2hFypV4Jf",
    "outputId": "b7db5425-f5ab-498e-fec7-2d2fe9b6bb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using ReLU: 96.78%\n",
      "Accuracy using Sigmoid: 96.65%\n",
      "Accuracy using Tanh: 95.97%\n",
      "Accuracy using LeakyReLU: 96.45%\n"
     ]
    }
   ],
   "source": [
    "# Define a list of activation functions to test\n",
    "activation_functions = {\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'Sigmoid': nn.Sigmoid(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'LeakyReLU': nn.LeakyReLU(negative_slope=0.1),\n",
    "    # Add more activation functions as needed\n",
    "}\n",
    "\n",
    "# Training and evaluation loop\n",
    "for activation_name, activation_func in activation_functions.items():\n",
    "    # Reinitialize the model for each activation function\n",
    "    class ModifiedMLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ModifiedMLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(28 * 28, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 10)\n",
    "            self.activation = activation_func  # Apply the activation function\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = self.activation(self.fc1(x))\n",
    "            x = self.activation(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = ModifiedMLP()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reinitialize optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy using {activation_name}: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2aOnoKQYOaP"
   },
   "source": [
    "The comparable accuracy levels achieved by different activation functions can be attributed to their underlying mathematical properties and suitability for the task at hand. ReLU (Rectified Linear Unit), known for its simplicity and effectiveness in mitigating the vanishing gradient problem, demonstrated the highest accuracy at 96.78%. Its ability to efficiently model non-linearities in the data likely contributed to its superior performance. Similarly, Sigmoid, which squashes values between 0 and 1, and Tanh, which squashes values between -1 and 1, performed well, albeit marginally lower than ReLU. These functions, while effective in certain scenarios like binary classification and data normalization, respectively, may have slightly lagged behind ReLU due to their tendency to saturate at extreme input values, leading to gradient vanishing or exploding issues. LeakyReLU, offering a small, non-zero gradient for negative inputs, addressed the \"dying ReLU\" problem and achieved competitive accuracy. Overall, the marginal differences in accuracy among these activation functions indicate their overall suitability for the QMNIST dataset, with ReLU emerging as the most effective choice due to its simplicity and ability to model complex relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8Iy7w5Qa26i"
   },
   "source": [
    "# Testing Different Dropout Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyweJnpUYPzx",
    "outputId": "f1d3ce47-3cd5-4589-d814-4b3ea3048278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dropout probability 0.0: 96.55%\n",
      "Accuracy using dropout probability 0.2: 96.26%\n",
      "Accuracy using dropout probability 0.5: 93.90%\n"
     ]
    }
   ],
   "source": [
    "# Define a list of dropout probabilities to test\n",
    "dropout_probs = [0.0, 0.2, 0.5]  # dropout probabilities\n",
    "\n",
    "# Training and evaluation loop\n",
    "for dropout_prob in dropout_probs:\n",
    "    # Define the modified model with dropout\n",
    "    class ModifiedMLP(nn.Module):\n",
    "        def __init__(self, dropout_prob):\n",
    "            super(ModifiedMLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(28 * 28, 128)\n",
    "            self.dropout1 = nn.Dropout(p=dropout_prob)  # Dropout layer\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.dropout2 = nn.Dropout(p=dropout_prob)  # Dropout layer\n",
    "            self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.dropout1(x)  # Apply dropout\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.dropout2(x)  # Apply dropout\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = ModifiedMLP(dropout_prob)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reinitialize optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy using dropout probability {dropout_prob}: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVWXtF4pazRf"
   },
   "source": [
    "Firstly, with a dropout probability of 0.0, where no dropout was applied, the model achieved the highest accuracy of 96.55%. This outcome suggests that for this specific model architecture and dataset, dropout regularization might not be necessary, as the model is capable of achieving high performance without it. However, when a dropout probability of 0.2 was introduced, resulting in the random zeroing-out of 20% of activations during training, there was a slight reduction in accuracy to 96.26%. While dropout regularization is designed to prevent overfitting by introducing noise during training, it appears that in this scenario, a moderate dropout rate did not significantly improve performance and may have even hindered it slightly. Conversely, employing a higher dropout probability of 0.5 led to a more pronounced decrease in accuracy to 93.90%. With half of the activations randomly zeroed out during training, the model may have suffered from increased underfitting, resulting in a notable drop in performance. Overall, these findings highlight the importance of careful experimentation and parameter tuning to determine the optimal dropout probability for a given model and dataset combination. While dropout regularization can be effective in preventing overfitting, its application should be tailored to the specific characteristics of the problem at hand to ensure optimal performance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
